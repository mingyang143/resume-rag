import time
import psycopg2
from ..ingestion.helpers import connect_postgres, load_env_vars
from typing import Dict, List, Tuple, Optional
import streamlit as st
from .helpers import connect_postgres, load_env_vars
import pandas as pd

def get_database_overview() -> Optional[Dict]:
    """
    Get comprehensive database statistics and overview information.
    
    Returns:
        Dictionary containing database statistics or None if error occurs
    """
    try:
        env = load_env_vars()
        conn = connect_postgres(env)
        cur = conn.cursor()
        
        # Get total records
        cur.execute("SELECT COUNT(*) FROM public.resumes_metadata;")
        total_metadata = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM public.resumes_normal;")
        total_normal = cur.fetchone()[0]
        
        # Get unique candidates
        cur.execute("SELECT COUNT(DISTINCT candidate_key) FROM public.resumes_metadata;")
        unique_candidates = cur.fetchone()[0]
        
        
        # Get skills distribution
        cur.execute("""
            SELECT unnest(skills_categories) as skill, COUNT(*) as count
            FROM public.resumes_normal 
            WHERE skills_categories IS NOT NULL 
            GROUP BY skill 
            ORDER BY count DESC 
            LIMIT 10;
        """)
        top_skills = cur.fetchall()
        
        # Get university distribution
        cur.execute("""
            SELECT university, COUNT(*) as count
            FROM public.resumes_metadata 
            WHERE university IS NOT NULL 
            GROUP BY university 
            ORDER BY count DESC 
            LIMIT 5;
        """)
        top_universities = cur.fetchall()
        
        # Get employment type distribution
        cur.execute("""
            SELECT part_or_full, COUNT(*) as count
            FROM public.resumes_metadata 
            WHERE part_or_full IS NOT NULL 
            GROUP BY part_or_full 
            ORDER BY count DESC;
        """)
        employment_distribution = cur.fetchall()
        
        # Get citizenship distribution
        cur.execute("""
            SELECT citizenship, COUNT(*) as count
            FROM public.resumes_metadata 
            WHERE citizenship IS NOT NULL 
            GROUP BY citizenship 
            ORDER BY count DESC;
        """)
        citizenship_distribution = cur.fetchall()
        
        # Get salary distribution
        cur.execute("""
            SELECT 
                CASE 
                    WHEN salary = 'any' THEN 'Flexible'
                    WHEN salary ~ '^[0-9]+$' THEN
                        CASE 
                            WHEN CAST(salary AS INTEGER) < 1000 THEN '< $1000'
                            WHEN CAST(salary AS INTEGER) < 1200 THEN '$1000-1200'
                            WHEN CAST(salary AS INTEGER) < 1400 THEN '$1200-1400'
                            WHEN CAST(salary AS INTEGER) < 1600 THEN '$1400-1600'
                            ELSE '$1600+'
                        END
                    ELSE 'Other'
                END as salary_range,
                COUNT(*) as count
            FROM public.resumes_metadata 
            WHERE salary IS NOT NULL 
            GROUP BY salary_range 
            ORDER BY count DESC;
        """)
        salary_distribution = cur.fetchall()
        
        cur.close()
        conn.close()
        
        return {
            'total_metadata': total_metadata,
            'total_normal': total_normal,
            'unique_candidates': unique_candidates,
            'top_skills': top_skills,
            'top_universities': top_universities,
            'employment_distribution': employment_distribution,
            'citizenship_distribution': citizenship_distribution,
            'salary_distribution': salary_distribution
        }
        
    except Exception as e:
        st.error(f"Error fetching database overview: {e}")
        return None

# def render_overview_dashboard() -> None:
#     """
#     Render the complete overview dashboard in Streamlit.
#     This is a comprehensive view of the entire database.
#     """
#     st.markdown("### ðŸ“Š Database Overview Dashboard")
#     st.caption("Comprehensive view of your resume database statistics and insights")
    
#     # Fetch database stats
#     db_overview = get_database_overview()
    
#     if not db_overview:
#         st.error("âŒ Unable to fetch database overview")
#         return
    
#     # === TOP METRICS ROW ===
#     col1, col2, col3, col4 = st.columns(4)
#     with col1:
#         st.metric("ðŸ“„ Total Resumes", db_overview['total_metadata'])
#     with col2:
#         st.metric("ðŸ” Processed Resumes", db_overview['total_normal'])
#     with col3:
#         st.metric("ðŸ‘¥ Unique Candidates", db_overview['unique_candidates'])
#     with col4:
#         sync_rate = f"{(db_overview['total_normal']/max(db_overview['total_metadata'], 1)*100):.1f}%"
#         st.metric("ðŸ”„ Sync Rate", sync_rate)
    
#     st.markdown("---")
    
#     # === DISTRIBUTIONS AND ANALYTICS ===
#     tab1, tab2 = st.tabs(["ðŸ“Š Demographics", "ðŸ› ï¸ Skills & Experience"])
    
#     with tab1:
#         col1, col2 = st.columns(2)
        
#         with col1:
#             st.markdown("#### ðŸŽ“ University Distribution")
#             if db_overview['top_universities']:
#                 uni_data = {
#                     "University": [row[0] for row in db_overview['top_universities']],
#                     "Count": [row[1] for row in db_overview['top_universities']]
#                 }
#                 st.dataframe(uni_data, hide_index=True, use_container_width=True)
#             else:
#                 st.info("No university data available")
            
#             st.markdown("#### ðŸŒ Citizenship Distribution")
#             if db_overview['citizenship_distribution']:
#                 citizen_data = {
#                     "Citizenship": [row[0] for row in db_overview['citizenship_distribution']],
#                     "Count": [row[1] for row in db_overview['citizenship_distribution']]
#                 }
#                 st.dataframe(citizen_data, hide_index=True, use_container_width=True)
                
#                 # Show as pie chart
#                 st.bar_chart(dict(db_overview['citizenship_distribution']))
#             else:
#                 st.info("No citizenship data available")
        
#         with col2:
#             st.markdown("#### ðŸ‘” Employment Type Distribution")
#             if db_overview['employment_distribution']:
#                 emp_data = {
#                     "Type": [row[0] for row in db_overview['employment_distribution']],
#                     "Count": [row[1] for row in db_overview['employment_distribution']]
#                 }
#                 st.dataframe(emp_data, hide_index=True, use_container_width=True)
                
#                 # Show as bar chart
#                 st.bar_chart(dict(db_overview['employment_distribution']))
#             else:
#                 st.info("No employment type data available")
            
#             st.markdown("#### ðŸ’° Salary Distribution")
#             if db_overview['salary_distribution']:
#                 salary_data = {
#                     "Range": [row[0] for row in db_overview['salary_distribution']],
#                     "Count": [row[1] for row in db_overview['salary_distribution']]
#                 }
#                 st.dataframe(salary_data, hide_index=True, use_container_width=True)
#             else:
#                 st.info("No salary data available")
    
#     with tab2:
#         col1, col2 = st.columns([2, 1])
        
#         with col1:
#             st.markdown("#### ðŸ› ï¸ Top Skills")
#             if db_overview['top_skills']:
#                 skills_data = {
#                     "Skill": [row[0] for row in db_overview['top_skills']],
#                     "Candidates": [row[1] for row in db_overview['top_skills']]
#                 }
#                 st.dataframe(skills_data, hide_index=True, use_container_width=True, height=400)
                
#                 # Show as horizontal bar chart
#                 skills_dict = {row[0]: row[1] for row in db_overview['top_skills']}
#                 st.bar_chart(skills_dict)
#             else:
#                 st.info("No skills data available")
        
#         with col2:
#             st.markdown("#### ðŸ“ˆ Quick Stats")
            
#             # Additional calculated metrics
#             if db_overview['total_metadata'] > 0:
#                 avg_resumes_per_candidate = db_overview['total_metadata'] / db_overview['unique_candidates']
#                 st.metric("ðŸ“Š Avg Resumes/Candidate", f"{avg_resumes_per_candidate:.1f}")
            
#             if db_overview['top_skills']:
#                 total_skill_mentions = sum(row[1] for row in db_overview['top_skills'])
#                 st.metric("ðŸŽ¯ Top 10 Skills Total", total_skill_mentions)
                
#                 most_popular_skill = db_overview['top_skills'][0]
#                 st.metric("ðŸ¥‡ Most Popular Skill", f"{most_popular_skill[0]} ({most_popular_skill[1]})")
            
#             # Data quality indicators
#             processing_completeness = f"{sync_rate}"
#             st.metric("âœ… Processing Complete", processing_completeness)
    
    
def render_overview_dashboard() -> None:
    """
    Render the complete overview dashboard in Streamlit.
    This is a comprehensive view of the entire database.
    """
    st.markdown("### ðŸ“Š Database Overview Dashboard")
    st.caption("Comprehensive view of your resume database statistics and insights")
    
    # Fetch database stats
    db_overview = get_database_overview()
    
    if not db_overview:
        print("âŒ Unable to fetch database overview")
        return
    
    # === TOP METRICS ROW ===
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ðŸ“„ Total Resumes", db_overview['total_metadata'])
    with col2:
        st.metric("ðŸ” Processed Resumes", db_overview['total_normal'])
    with col3:
        st.metric("ðŸ‘¥ Unique Candidates", db_overview['unique_candidates'])
    with col4:
        sync_rate = f"{(db_overview['total_normal']/max(db_overview['total_metadata'], 1)*100):.1f}%"
        st.metric("ðŸ”„ Sync Rate", sync_rate)
    
    st.markdown("---")
    
    # === DISTRIBUTIONS AND ANALYTICS ===
    tab1, tab2, tab3 = st.tabs(["ðŸ“Š Demographics", "ðŸ› ï¸ Skills & Experience", "ðŸ’¬ Chat with All Candidates"])
    
    with tab1:
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ðŸŽ“ University Distribution")
            if db_overview['top_universities']:
                uni_data = {
                    "University": [row[0] for row in db_overview['top_universities']],
                    "Count": [row[1] for row in db_overview['top_universities']]
                }
                st.dataframe(uni_data, hide_index=True, use_container_width=True)
            else:
                st.info("No university data available")
            
            st.markdown("#### ðŸŒ Citizenship Distribution")
            if db_overview['citizenship_distribution']:
                citizen_data = {
                    "Citizenship": [row[0] for row in db_overview['citizenship_distribution']],
                    "Count": [row[1] for row in db_overview['citizenship_distribution']]
                }
                st.dataframe(citizen_data, hide_index=True, use_container_width=True)
                
                # Show as pie chart
                st.bar_chart(dict(db_overview['citizenship_distribution']))
            else:
                st.info("No citizenship data available")
        
        with col2:
            st.markdown("#### ðŸ‘” Employment Type Distribution")
            if db_overview['employment_distribution']:
                emp_data = {
                    "Type": [row[0] for row in db_overview['employment_distribution']],
                    "Count": [row[1] for row in db_overview['employment_distribution']]
                }
                st.dataframe(emp_data, hide_index=True, use_container_width=True)
                
                # Show as bar chart
                st.bar_chart(dict(db_overview['employment_distribution']))
            else:
                st.info("No employment type data available")
            
            st.markdown("#### ðŸ’° Salary Distribution")
            if db_overview['salary_distribution']:
                salary_data = {
                    "Range": [row[0] for row in db_overview['salary_distribution']],
                    "Count": [row[1] for row in db_overview['salary_distribution']]
                }
                st.dataframe(salary_data, hide_index=True, use_container_width=True)
            else:
                st.info("No salary data available")
    
    with tab2:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("#### ðŸ› ï¸ Top Skills")
            if db_overview['top_skills']:
                skills_data = {
                    "Skill": [row[0] for row in db_overview['top_skills']],
                    "Candidates": [row[1] for row in db_overview['top_skills']]
                }
                st.dataframe(skills_data, hide_index=True, use_container_width=True, height=400)
                
                # Show as horizontal bar chart
                skills_dict = {row[0]: row[1] for row in db_overview['top_skills']}
                st.bar_chart(skills_dict)
            else:
                st.info("No skills data available")
        
        with col2:
            st.markdown("#### ðŸ“ˆ Quick Stats")
            
            # Additional calculated metrics
            if db_overview['total_metadata'] > 0:
                avg_resumes_per_candidate = db_overview['total_metadata'] / db_overview['unique_candidates']
                st.metric("ðŸ“Š Avg Resumes/Candidate", f"{avg_resumes_per_candidate:.1f}")
            
            if db_overview['top_skills']:
                total_skill_mentions = sum(row[1] for row in db_overview['top_skills'])
                st.metric("ðŸŽ¯ Top 10 Skills Total", total_skill_mentions)
                
                most_popular_skill = db_overview['top_skills'][0]
                st.metric("ðŸ¥‡ Most Popular Skill", f"{most_popular_skill[0]} ({most_popular_skill[1]})")
            
            # Data quality indicators
            processing_completeness = f"{sync_rate}"
            st.metric("âœ… Processing Complete", processing_completeness)
    
    with tab3:
        # NEW CHAT INTERFACE FOR ALL CANDIDATES
        render_overview_chat_interface()
    
    st.markdown("---")
        
def render_overview_chat_interface():
    """
    Render a chat interface for talking to all candidates in the database.
    """
    print("ðŸ’¬" * 30)
    print("render_overview_chat_interface() CALLED!")
    print("ðŸ’¬" * 30)
    
    st.markdown("#### ðŸ’¬ Chat with All Candidates")
    st.caption("Ask questions about any candidate or send emails directly from here")
    
    # Get all candidate keys and filenames from database
    try:
        env = load_env_vars()
        conn = connect_postgres(env)
        cur = conn.cursor()
        
        # Get all candidates and their files
        cur.execute("""
            SELECT DISTINCT rm.filename, rm.candidate_key
            FROM public.resumes_metadata rm
            WHERE rm.candidate_key IS NOT NULL
            ORDER BY rm.candidate_key, rm.filename;
        """)
        all_records = cur.fetchall()
        
        cur.close()
        conn.close()
        
        if not all_records:
            st.info("ðŸ“­ No candidates found in the database.")
            return
        
        # Extract all filenames and candidate keys
        all_filenames = [record[0] for record in all_records]
        all_candidate_keys = list(set([record[1] for record in all_records]))
        
        print(f"ðŸ’¬ Found {len(all_candidate_keys)} candidates with {len(all_filenames)} total files")
        
        
        # Show summary with candidate keys
        st.info(
            f"ðŸ’¬ Ready to chat about **{len(all_candidate_keys)} candidates** "
            f"with **{len(all_filenames)} total files**\n\n"
            f"**Candidate Keys:** {', '.join(sorted(all_candidate_keys))}"
        )
        
        # Initialize session state - use a unique key for overview chat
        chat_key = "overview_chat_all_candidates"
        if chat_key not in st.session_state:
            st.session_state[chat_key] = []

        # STEP 1: Display chat history FIRST
        for msg in st.session_state[chat_key]:
            st.chat_message(msg["role"]).write(msg["content"])

        

        # STEP 3: Process input when received (BEFORE creating input box)
        # Move the user_input definition to the very end
        
        # Initialize user_input from session state to handle processing
        if 'pending_overview_input' in st.session_state:
            user_input = st.session_state['pending_overview_input']
            del st.session_state['pending_overview_input']
            
            print(f"ðŸ’¬ User input received: {user_input}")
            
            # Add user message to history
            st.session_state[chat_key].append({"role": "user", "content": user_input})
            st.chat_message("user").write(user_input)
            
            # Import email service here to avoid circular imports
            from ..backend.email_service import EmailService
            from .email_ui_helpers import process_user_input
            
            email_service = EmailService()
            
            # Process the user input using the same helper function
            reply = process_user_input(user_input, all_candidate_keys, all_candidate_keys, email_service)
            
            print(f"ðŸ’¬ AI reply: {reply[:100]}...")
            
            # Add assistant response to history and display
            st.session_state[chat_key].append({"role": "assistant", "content": reply})
            st.chat_message("assistant").write(reply)

        # STEP 4: User input box AT THE VERY BOTTOM
        user_input = st.chat_input("Ask me anything about these candidates...", key="overview_input")
        
        # If user entered something, store it for next run
        if user_input:
            st.session_state['pending_overview_input'] = user_input
            st.rerun()
            
        # STEP 2: Show helpful examples AFTER chat history
        with st.expander("ðŸ’¡ Example questions you can ask"):
            st.markdown("""
            **Skill-based queries:**
            - "Find candidates with Python and machine learning experience"
            - "Who has React and Node.js skills?"
            - "Which candidates know cloud computing?"
            
            **Candidate-specific queries:**
            - "What's Leon's educational background?"
            - "Tell me about Xiang's work experience"
            - "What projects has DIAN worked on?"
            
            **Email commands:**
            
            **Job Offers:**
            - "Send offer email to mingyang for software engineer position, starting January 15th, salary $2000/month, 6 months"
            - "Email offer to john for data analyst role, beginning February 1st, salary 2500, 4 months"
            - "Offer alice the UI/UX designer position, start Monday, $1800/month, 3 months"
            - "Send offer to bob for summer internship, starting June 1st, salary $1500/month"
            
            ***Special Program Offers (ATAP & SIP):***
            - "Send offer to lisa for ATAP program, starting March 1st, salary $2500/month"
            - "Email offer to mike for SIP program, salary 1800, start May 12th"
            
            **Interview Invitations:**
            - "Invite Sarah for interview tomorrow at 2pm via Zoom, 45 minutes, AI software developer"
            - "Send interview email to Mike for January 20th at 10am, in-person"
            - "Schedule interview with Lisa next Monday 3pm, online meeting, 30 minutes"
            
            **Job Rejection emails:**
            - "Send rejection letter to Alice"
            - "Reject Bob via email for data analyst position"
            """)
    
    except Exception as e:
        print(f"ðŸ’¬ Error in overview chat interface: {e}")
        
def get_quick_stats() -> Optional[Dict[str, int]]:
    """
    Get quick database statistics for use in other parts of the application.
    
    Returns:
        Dictionary with basic statistics or None if error occurs
    """
    try:
        env = load_env_vars()
        conn = connect_postgres(env)
        cur = conn.cursor()
        
        cur.execute("SELECT COUNT(*) FROM public.resumes_metadata;")
        total_metadata = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM public.resumes_normal;")
        total_normal = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(DISTINCT candidate_key) FROM public.resumes_metadata;")
        unique_candidates = cur.fetchone()[0]
        
        cur.close()
        conn.close()
        
        return {
            'total_metadata': total_metadata,
            'total_normal': total_normal,
            'unique_candidates': unique_candidates
        }
        
    except Exception as e:
        st.error(f"Error fetching quick stats: {e}")
        return None
    
def get_all_candidate_keys() -> List[str]:
    """
    Get all unique candidate keys from both resumes_metadata and resumes_normal tables.
    
    Returns:
        List of unique candidate keys
    """
    try:
        env = load_env_vars()
        conn = connect_postgres(env)
        cur = conn.cursor()
        
        # Get candidate keys from both tables
        cur.execute("""
            SELECT DISTINCT candidate_key 
            FROM (
                SELECT candidate_key FROM public.resumes_metadata 
                WHERE candidate_key IS NOT NULL
                UNION
                SELECT candidate_key FROM public.resumes_normal 
                WHERE candidate_key IS NOT NULL
            ) AS combined_keys
            ORDER BY candidate_key;
        """)
        
        candidate_keys = [row[0] for row in cur.fetchall()]
        
        cur.close()
        conn.close()
        
        return candidate_keys
        
    except Exception as e:
        st.error(f"Error fetching candidate keys: {e}")
        return []

def get_candidate_details(candidate_key: str) -> Dict:
    """
    Get detailed information about a specific candidate from both tables.
    
    Args:
        candidate_key: The candidate identifier
        
    Returns:
        Dictionary with candidate details from both tables
    """
    try:
        env = load_env_vars()
        conn = connect_postgres(env)
        cur = conn.cursor()
        
        # Get metadata records
        cur.execute("""
            SELECT filename, university, applied_position, salary, part_or_full, citizenship
            FROM public.resumes_metadata 
            WHERE candidate_key = %s;
        """, (candidate_key,))
        metadata_records = cur.fetchall()
        
        # Get normal records
        cur.execute("""
            SELECT filename, skills_categories
            FROM public.resumes_normal 
            WHERE candidate_key = %s;
        """, (candidate_key,))
        normal_records = cur.fetchall()
        
        cur.close()
        conn.close()
        
        return {
            'candidate_key': candidate_key,
            'metadata_records': metadata_records,
            'normal_records': normal_records,
            'total_files': len(set([r[0] for r in metadata_records] + [r[0] for r in normal_records]))
        }
        
    except Exception as e:
        st.error(f"Error fetching candidate details: {e}")
        return {}

# def delete_candidate_records(candidate_key: str) -> Dict[str, int]:
#     """
#     Delete all records for a specific candidate from both tables.
    
#     Args:
#         candidate_key: The candidate identifier to delete
        
#     Returns:
#         Dictionary with deletion counts from both tables
#     """
#     try:
#         env = load_env_vars()
#         conn = connect_postgres(env)
#         cur = conn.cursor()
        
#         # Delete from resumes_metadata
#         cur.execute("""
#             DELETE FROM public.resumes_metadata 
#             WHERE candidate_key = %s;
#         """, (candidate_key,))
#         metadata_deleted = cur.rowcount
        
#         # Delete from resumes_normal
#         cur.execute("""
#             DELETE FROM public.resumes_normal 
#             WHERE candidate_key = %s;
#         """, (candidate_key,))
#         normal_deleted = cur.rowcount
        
#         conn.commit()
#         cur.close()
#         conn.close()
        
#         return {
#             'metadata_deleted': metadata_deleted,
#             'normal_deleted': normal_deleted,
#             'total_deleted': metadata_deleted + normal_deleted
#         }
        
#     except Exception as e:
#         st.error(f"Error deleting candidate records: {e}")
#         return {'metadata_deleted': 0, 'normal_deleted': 0, 'total_deleted': 0}

def delete_candidate_records(candidate_key: str) -> Dict[str, int]:
    """
    Delete all records for a specific candidate from metadata, normal, and score tables.
    Also delete PDF files from the server.
    """
    try:
        # Import PDF server
        from ..frontend.pdf_server import pdf_server
        
        env = load_env_vars()
        conn = connect_postgres(env)
        cur = conn.cursor()

        # Get PDF URLs before deletion
        cur.execute("""
            SELECT pdf_url FROM public.resumes_metadata WHERE candidate_key = %s AND pdf_url IS NOT NULL
            UNION
            SELECT pdf_url FROM public.resumes_normal WHERE candidate_key = %s AND pdf_url IS NOT NULL
        """, (candidate_key, candidate_key))
        
        pdf_urls = [row[0] for row in cur.fetchall()]
        
        # Delete PDF files from server
        for pdf_url in pdf_urls:
            pdf_server.delete_pdf(pdf_url)
        
        # 1) Delete from resumes_metadata
        cur.execute("DELETE FROM public.resumes_metadata WHERE candidate_key = %s;", (candidate_key,))
        metadata_deleted = cur.rowcount

        # 2) Delete from resumes_normal
        cur.execute("DELETE FROM public.resumes_normal WHERE candidate_key = %s;", (candidate_key,))
        normal_deleted = cur.rowcount

        # 3) Delete from resume_category_score
        cur.execute("DELETE FROM public.resume_category_score WHERE candidate_key = %s;", (candidate_key,))
        score_deleted = cur.rowcount

        conn.commit()
        cur.close()
        conn.close()

        print(f"âœ… Deleted candidate {candidate_key} and {len(pdf_urls)} PDF files")

        return {
            'metadata_deleted': metadata_deleted,
            'normal_deleted': normal_deleted,
            'score_deleted': score_deleted,
            'total_deleted': metadata_deleted + normal_deleted + score_deleted,
        }

    except Exception as e:
        print(f"âŒ Error deleting candidate: {e}")
        return {'metadata_deleted': 0, 'normal_deleted': 0, 'score_deleted': 0, 'total_deleted': 0}


def render_deletion_tab() -> None:
    """
    Render the deletion tab with candidate management functionality.
    """
    st.markdown("### ðŸ—‘ï¸ Candidate Record Deletion")
    st.caption("âš ï¸ **Warning**: This will permanently delete all records for the selected candidate from both tables!")
    
    # Get all candidate keys
    candidate_keys = get_all_candidate_keys()
    
    if not candidate_keys:
        st.info("ðŸ“­ No candidate records found in the database.")
        return
    
    st.info(f"ðŸ“Š Found **{len(candidate_keys)}** candidates in the database")
    
    # Create two columns for selection and preview
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.markdown("#### ðŸ‘¤ Select Candidate")
        
        # Selectbox for candidate selection
        selected_candidate = st.selectbox(
            "Choose candidate to delete:",
            options=[""] + candidate_keys,
            index=0,
            help="Select a candidate to view their details and delete their records"
        )
    
    with col2:
        if selected_candidate:
            st.markdown("#### ðŸ“‹ Candidate Details")
            
            # Get detailed information about the selected candidate
            candidate_details = get_candidate_details(selected_candidate)
            
            if candidate_details:
                # Display summary metrics
                col_a, col_b, col_c = st.columns(3)
                with col_a:
                    st.metric("ðŸ“ Total Files", candidate_details['total_files'])
                with col_b:
                    st.metric("ðŸ“Š Metadata Records", len(candidate_details['metadata_records']))
                with col_c:
                    st.metric("ðŸ” Skills Records", len(candidate_details['normal_records']))
                
                # Show detailed records
                if candidate_details['metadata_records']:
                    st.markdown("##### ðŸ“Š Metadata Records")
                    metadata_df = {
                        "Filename": [r[0] for r in candidate_details['metadata_records']],
                        "University": [r[1] or "N/A" for r in candidate_details['metadata_records']],
                        "Position": [r[2] or "N/A" for r in candidate_details['metadata_records']],
                        "Salary": [r[3] or "N/A" for r in candidate_details['metadata_records']],
                        "Employment": [r[4] or "N/A" for r in candidate_details['metadata_records']],
                        "Citizenship": [r[5] or "N/A" for r in candidate_details['metadata_records']]
                    }
                    st.dataframe(metadata_df, hide_index=True, use_container_width=True)
                
                if candidate_details['normal_records']:
                    st.markdown("##### ðŸ› ï¸ Skills Records")
                    normal_df = {
                        "Filename": [r[0] for r in candidate_details['normal_records']],
                        "Skills": [", ".join(r[1][:5]) + ("..." if len(r[1]) > 5 else "") if r[1] else "N/A" 
                                 for r in candidate_details['normal_records']]
                    }
                    st.dataframe(normal_df, hide_index=True, use_container_width=True)
                
                st.markdown("---")
                
                # Deletion section with confirmation
                st.markdown("##### âš ï¸ Danger Zone")
                
                # Two-step confirmation process
                confirm_checkbox = st.checkbox(
                    f"I understand that deleting **{selected_candidate}** will permanently remove all their records",
                    key=f"confirm_{selected_candidate}"
                )
                
                if confirm_checkbox:
                    st.error("ðŸš¨ **Final Warning**: This action cannot be undone!")
                    
                    delete_button = st.button(
                        f"ðŸ—‘ï¸ DELETE {selected_candidate}",
                        type="primary",
                        use_container_width=True,
                        key=f"delete_{selected_candidate}"
                    )
                    
                    if delete_button:
                        with st.spinner(f"ðŸ—‘ï¸ Deleting all records for {selected_candidate}..."):
                            deletion_result = delete_candidate_records(selected_candidate)
                        
                        if deletion_result['total_deleted'] > 0:
                            st.success(
                                f"âœ… **Successfully deleted {selected_candidate}!**\n\n"
                                f"ðŸ“Š Metadata records deleted: {deletion_result['metadata_deleted']}\n\n"
                                f"ðŸ” Skills records deleted: {deletion_result['normal_deleted']}\n\n"
                                f"ðŸ·ï¸ Categoryâ€score rows deleted: {deletion_result['score_deleted']}\n\n"
                                f"ðŸ“ Total records deleted: {deletion_result['total_deleted']}"
                            )
                            
                            # Clear the selection by rerunning
                            st.rerun()
                        else:
                            st.error("âŒ No records were deleted. Please check if the candidate exists.")
            
            else:
                st.error("âŒ Could not retrieve candidate details.")
        else:
            st.info("ðŸ‘† Select a candidate from the left to view their details")
    
    # Add refresh button
    st.markdown("---")
    col_refresh1, col_refresh2, col_refresh3 = st.columns([1, 1, 1])
    with col_refresh2:
        if st.button("ðŸ”„ Refresh Candidate List", use_container_width=True):
            st.rerun()
            
# def render_skills_management_tab() -> None:
#     """
#     Render the skills management tab for viewing and managing skills categories.
#     """
#     st.markdown("### ðŸ› ï¸ Manage Skill Categories")
#     conn = connect_postgres(load_env_vars())
#     cur  = conn.cursor()

#     # 1) Show existing categories
#     st.write("#### Existing Categories")
#     cur.execute("SELECT id, name FROM skill_category ORDER BY name;")
#     rows = cur.fetchall()
#     if rows:
#         st.table({
#             "ID":   [r[0] for r in rows],
#             "Name": [r[1].title() for r in rows],
#         })
        
#         # Show count
#         st.info(f"ðŸ“Š Total categories: **{len(rows)}**")
#     else:
#         st.info("No skill categories defined yet.")

#     st.markdown("---")

#     # 2) Show previous alert once
#     if st.session_state.get("cat_success"):
#         st.success(st.session_state["cat_success"])
#         del st.session_state["cat_success"]

#     # 3) Clear the text_input on the one run after adding
#     if st.session_state.get("cat_added", False):
#         default_new_cat = ""
#         del st.session_state["cat_added"]
#     else:
#         default_new_cat = st.session_state.get("new_cat_input", "")

#     # 4) Add a new category with existence check
#     st.markdown("#### âž• Add New Category")
#     new_cat = st.text_input(
#         "Add a new category",
#         placeholder="e.g. Web Development",
#         key="new_cat_input",
#         value=default_new_cat,
#     )
#     if st.button("âž• Add Category", key="add_cat_btn"):
#         cat = new_cat.strip()
#         if not cat:
#             st.error("Name cannot be empty.")
#         else:
#             # Try to insert, returning the name if inserted
#             cur.execute("""
#                 INSERT INTO skill_category(name)
#                 VALUES (LOWER(%s))
#                 ON CONFLICT(name) DO NOTHING
#                 RETURNING name;
#             """, (cat,))
#             result = cur.fetchone()
#             if result:
#                 # insertion happened
#                 conn.commit()
#                 st.session_state["cat_success"] = f"Added category: **{cat}**"
#                 st.session_state["cat_added"]   = True
#             else:
#                 # already existed
#                 st.session_state["cat_success"] = f"Category **{cat}** already exists."
#             st.rerun()

#     st.markdown("---")

#     # 5) Show previous delete alert once
#     if st.session_state.get("del_success"):
#         st.warning(st.session_state["del_success"])
#         del st.session_state["del_success"]

#     # 6) Delete an existing category
#     if rows:  # Only show if there are categories to delete
#         st.markdown("#### ðŸ—‘ï¸ Delete Individual Category")
#         to_delete = st.selectbox(
#             "Delete a category",
#             [r[1].title() for r in rows],
#             index=0 if rows else None
#         )
#         if st.button("ðŸ—‘ï¸ Delete Category", key="del_cat_btn"):
#             cur.execute(
#                 "DELETE FROM skill_category WHERE LOWER(name) = LOWER(%s);",
#                 (to_delete,)
#             )
#             conn.commit()
#             st.session_state["del_success"] = f"Deleted category: **{to_delete}**"
#             st.rerun()

#     st.markdown("---")

#     # 7) NEW: Delete All Categories section
#     st.markdown("#### ðŸ§¹ Bulk Delete All Categories")
#     st.warning("âš ï¸ This will permanently delete **all** skill categories. Use this before ingesting a new job description.")
    
#     # Show delete all success message
#     if st.session_state.get("delete_all_cats_success", False):
#         st.success("âœ… All skill categories have been deleted.")
#         del st.session_state["delete_all_cats_success"]

#     # Handle confirmation checkbox
#     if st.session_state.get("deleted_all_cats_once", False):
#         default_confirm_all = False
#         del st.session_state["deleted_all_cats_once"]
#     else:
#         default_confirm_all = st.session_state.get("confirm_delete_all_cats", False)

#     confirm_delete_all = st.checkbox(
#         "I understand this will delete all skill categories and cannot be undone",
#         value=default_confirm_all,
#         key="confirm_delete_all_cats",
#     )

#     if st.button("ðŸ—‘ï¸ DELETE ALL CATEGORIES", key="delete_all_cats_btn", type="secondary"):
#         if not confirm_delete_all:
#             st.error("You must check the confirmation box above to delete all categories.")
#         else:
#             try:
#                 # Count categories before deletion
#                 cur.execute("SELECT COUNT(*) FROM skill_category;")
#                 count_before = cur.fetchone()[0]
                
#                 # Delete all categories
#                 cur.execute("TRUNCATE TABLE skill_category RESTART IDENTITY CASCADE;")
#                 conn.commit()
                
#                 # Set success flags
#                 st.session_state["delete_all_cats_success"] = True
#                 st.session_state["deleted_all_cats_once"] = True
                
#                 st.rerun()
                
#             except Exception as e:
#                 st.error(f"âŒ Failed to delete all categories: {e}")

#     cur.close()
#     conn.close()

def render_skills_management_tab() -> None:
    """
    Render the skills management tab for viewing and managing skills categories.
    """
    print("ðŸ”§" * 30)
    print("render_skills_management_tab() CALLED!")
    print("ðŸ”§" * 30)
    
    st.markdown("### ðŸ› ï¸ Manage Skill Categories")
    conn = connect_postgres(load_env_vars())
    cur = conn.cursor()

    # 1) Show existing categories
    st.write("#### Existing Categories")
    cur.execute("SELECT id, name FROM skill_category ORDER BY name;")
    rows = cur.fetchall()
    
    print(f"ðŸ“Š Found {len(rows)} existing skill categories")
    
    if rows:
        st.table({
            "ID": [r[0] for r in rows],
            "Name": [r[1].title() for r in rows],
        })
        
        # Show count
        st.info(f"ðŸ“Š Total categories: **{len(rows)}**")
    else:
        st.info("No skill categories defined yet.")

    st.markdown("---")

    # 2) Show previous alert once
    if st.session_state.get("cat_success"):
        st.success(st.session_state["cat_success"])
        del st.session_state["cat_success"]

    # 3) Clear the text_input on the one run after adding
    if st.session_state.get("cat_added", False):
        default_new_cat = ""
        del st.session_state["cat_added"]
    else:
        default_new_cat = st.session_state.get("new_cat_input", "")

    # 4) Add a new category with existence check
    st.markdown("#### âž• Add New Category")
    new_cat = st.text_input(
        "Add a new category",
        placeholder="e.g. Web Development",
        key="new_cat_input",
        value=default_new_cat,
    )
    if st.button("âž• Add Category", key="add_cat_btn"):
        cat = new_cat.strip()
        print(f"ðŸ†• Attempting to add category: '{cat}'")
        
        if not cat:
            print("âŒ Category name is empty")
            st.session_state["cat_success"] = "âŒ Name cannot be empty."
        else:
            try:
                # Try to insert, returning the name if inserted
                cur.execute("""
                    INSERT INTO skill_category(name)
                    VALUES (LOWER(%s))
                    ON CONFLICT(name) DO NOTHING
                    RETURNING name;
                """, (cat,))
                result = cur.fetchone()
                
                if result:
                    # insertion happened
                    conn.commit()
                    print(f"âœ… Successfully added category: '{cat}'")
                    st.session_state["cat_success"] = f"Added category: **{cat}**"
                    st.session_state["cat_added"] = True
                else:
                    # already existed
                    print(f"âš ï¸ Category already exists: '{cat}'")
                    st.session_state["cat_success"] = f"Category **{cat}** already exists."
                
                st.rerun()
                
            except Exception as e:
                print(f"âŒ Error adding category: {e}")
                st.session_state["cat_success"] = f"âŒ Error adding category: {e}"
                st.rerun()

    st.markdown("---")

    # 5) Show previous delete alert once
    if st.session_state.get("del_success"):
        st.info(st.session_state["del_success"])  # Changed from st.warning to st.info
        del st.session_state["del_success"]

    # 6) Delete an existing category
    if rows:  # Only show if there are categories to delete
        st.markdown("#### ðŸ—‘ï¸ Delete Individual Category")
        to_delete = st.selectbox(
            "Delete a category",
            [r[1].title() for r in rows],
            index=0 if rows else None
        )
        if st.button("ðŸ—‘ï¸ Delete Category", key="del_cat_btn"):
            print(f"ðŸ—‘ï¸ Attempting to delete category: '{to_delete}'")
            
            try:
                cur.execute(
                    "DELETE FROM skill_category WHERE LOWER(name) = LOWER(%s);",
                    (to_delete,)
                )
                deleted_count = cur.rowcount
                conn.commit()
                
                print(f"âœ… Successfully deleted {deleted_count} category: '{to_delete}'")
                st.session_state["del_success"] = f"Deleted category: **{to_delete}**"
                st.rerun()
                
            except Exception as e:
                print(f"âŒ Error deleting category: {e}")
                st.session_state["del_success"] = f"âŒ Error deleting category: {e}"
                st.rerun()

    st.markdown("---")

    # 7) NEW: Delete All Categories section
    st.markdown("#### ðŸ§¹ Bulk Delete All Categories")
    st.info("âš ï¸ This will permanently delete **all** skill categories. Use this before ingesting a new job description.")
    
    # Show delete all success message
    if st.session_state.get("delete_all_cats_success", False):
        st.success("âœ… All skill categories have been deleted.")
        del st.session_state["delete_all_cats_success"]

    # Handle confirmation checkbox
    if st.session_state.get("deleted_all_cats_once", False):
        default_confirm_all = False
        del st.session_state["deleted_all_cats_once"]
    else:
        default_confirm_all = st.session_state.get("confirm_delete_all_cats", False)

    confirm_delete_all = st.checkbox(
        "I understand this will delete all skill categories and cannot be undone",
        value=default_confirm_all,
        key="confirm_delete_all_cats",
    )

    if st.button("ðŸ—‘ï¸ DELETE ALL CATEGORIES", key="delete_all_cats_btn", type="secondary"):
        if not confirm_delete_all:
            print("âŒ User tried to delete all without confirmation")
            st.session_state["delete_all_cats_success"] = False
            st.session_state["del_success"] = "âŒ You must check the confirmation box above to delete all categories."
            st.rerun()
        else:
            print("ðŸ—‘ï¸ Attempting to delete ALL categories...")
            
            try:
                # Count categories before deletion
                cur.execute("SELECT COUNT(*) FROM skill_category;")
                count_before = cur.fetchone()[0]
                print(f"ðŸ“Š Found {count_before} categories to delete")
                
                # Delete all categories
                cur.execute("TRUNCATE TABLE skill_category RESTART IDENTITY CASCADE;")
                conn.commit()
                
                print(f"âœ… Successfully deleted all {count_before} categories")
                
                # Set success flags
                st.session_state["delete_all_cats_success"] = True
                st.session_state["deleted_all_cats_once"] = True
                
                st.rerun()
                
            except Exception as e:
                print(f"âŒ Error deleting all categories: {e}")
                st.session_state["del_success"] = f"âŒ Failed to delete all categories: {e}"
                st.rerun()

    cur.close()
    conn.close()
    print("ðŸ”§ render_skills_management_tab() completed")
    
   
# def render_score_table() -> None:
#     """
#     Render the skill category scores for each resume.
#     """
#     st.markdown("### ðŸ“ˆ Candidate Skill Category Scores")

#     # â€”â€“ Fetch data from Postgres â€”â€“
#     env  = load_env_vars()
#     conn = connect_postgres(env)
#     cur  = conn.cursor()
#     cur.execute("""
#         SELECT 
#           s.candidate_key || ' / ' || s.filename AS resume_id,
#           c.name AS category,
#           s.score
#         FROM resume_category_score s
#         JOIN skill_category c ON c.id = s.category_id
#     """)
#     rows = cur.fetchall()
#     cur.close()
#     conn.close()

#     if not rows:
#         st.info("No category scores yet.")
#     else:
#         # 1) Build the pivot table
#         df    = pd.DataFrame(rows, columns=["resume_id", "category", "score"])
#         pivot = (
#             df.pivot(index="resume_id", columns="category", values="score")
#               .fillna(0)
#               .astype(int)
#         )

#         # 2) Compute an â€œaverage scoreâ€ helper column and sort by it
#         pivot["avg_score"] = pivot.mean(axis=1)
#         pivot = pivot.sort_values("avg_score", ascending=False).drop("avg_score", axis=1)

#         # 3) Page through top N by average score
#         total = len(pivot)
#         show_n = st.slider(
#             "Show top N resumes by average score",
#             min_value=1,
#             max_value=min(50, total),
#             value=min(10, total)
#         )

#         # 4) Display and allow CSV download
#         display_df = pivot.head(show_n)
#         st.dataframe(display_df)
#         csv = display_df.to_csv().encode("utf-8")
#         st.download_button("â¬‡ï¸ Download CSV", csv, "category_scores.csv", "text/csv")
        

# def render_score_table() -> None:
#     """
#     Render the skill category scores for each resume with search and filters.
#     """
#     st.markdown("### ðŸ“ˆ Candidate Skill Category Scores")

#     # â€”â€“ Fetch data from Postgres â€”â€“
#     env  = load_env_vars()
#     conn = connect_postgres(env)
#     cur  = conn.cursor()
#     cur.execute("""
#         SELECT 
#           s.candidate_key || ' / ' || s.filename AS resume_id,
#           s.candidate_key,
#           c.name AS category,
#           s.score
#         FROM resume_category_score s
#         JOIN skill_category c ON c.id = s.category_id
#     """)
#     rows = cur.fetchall()
#     cur.close()
#     conn.close()

#     if not rows:
#         st.info("No category scores yet.")
#         return

#     # 1) Build the pivot table
#     df = pd.DataFrame(rows, columns=["resume_id", "candidate_key", "category", "score"])
#     pivot = (
#         df.pivot(index="resume_id", columns="category", values="score")
#           .fillna(0)
#           .astype(int)
#     )
    
#     # Add candidate_key column for filtering
#     candidate_mapping = df.drop_duplicates('resume_id').set_index('resume_id')['candidate_key']
#     pivot['candidate_key'] = candidate_mapping
    
#     # 2) Add average score column
#     skill_columns = [col for col in pivot.columns if col != 'candidate_key']
#     pivot["Average Score"] = pivot[skill_columns].mean(axis=1).round(2)
    
#     # 3) Reorder columns: candidate_key, Average Score, then skills (no duplicates)
#     other_skills = [col for col in skill_columns if col != 'Average Score']  
#     pivot = pivot[['candidate_key', 'Average Score'] + other_skills]
def render_score_table() -> None:
    """
    Render the skill category scores for each resume with search and filters.
    """
    st.markdown("### ðŸ“ˆ Candidate Skill Category Scores")

    # Enhanced query to fetch PDF URLs
    env  = load_env_vars()
    conn = connect_postgres(env)
    cur  = conn.cursor()
    cur.execute("""
        SELECT 
          s.candidate_key AS candidate_name,
          s.candidate_key,
          c.name AS category,
          s.score,
          rm.filename AS metadata_file,
          rm.pdf_url AS mikomiko_url,
          rn.filename AS resume_file,
          rn.pdf_url AS resume_url
        FROM resume_category_score s
        JOIN skill_category c ON c.id = s.category_id
        LEFT JOIN resumes_metadata rm ON s.candidate_key = rm.candidate_key
        LEFT JOIN resumes_normal rn ON s.candidate_key = rn.candidate_key
    """)
    rows = cur.fetchall()
    cur.close()
    conn.close()

    if not rows:
        st.info("No category scores yet.")
        return
    
    # Build file mappings with URLs using ALL 8 columns
    file_mappings = {}
    df_full = pd.DataFrame(rows, columns=[
        "candidate_name", "candidate_key", "category", "score", 
        "metadata_file", "mikomiko_url", "resume_file", "resume_url"
    ])
    
    for _, row in df_full.iterrows():
        candidate = row['candidate_name']
        if candidate not in file_mappings:
            file_mappings[candidate] = {
                'mikomiko_file': row['metadata_file'],
                'mikomiko_url': row['mikomiko_url'],
                'resume_file': row['resume_file'],
                'resume_url': row['resume_url']
            }
    
    # 1) Build the pivot table using candidate names (only need first 4 columns)
    df = pd.DataFrame(rows, columns=["candidate_name", "candidate_key", "category", "score", 
                                    "metadata_file", "mikomiko_url", "resume_file", "resume_url"])
    
    # Keep only the columns we need for the pivot
    df_pivot = df[["candidate_name", "candidate_key", "category", "score"]]
    
    pivot = (
        df_pivot.pivot(index="candidate_name", columns="category", values="score")
          .fillna(0)
          .astype(int)
    )
    
    # Add candidate_key column for filtering
    candidate_mapping = df_pivot.drop_duplicates('candidate_name').set_index('candidate_name')['candidate_key']
    pivot['candidate_key'] = candidate_mapping
    
    # 2) Add average score column
    skill_columns = [col for col in pivot.columns if col != 'candidate_key']
    pivot["Average Score"] = pivot[skill_columns].mean(axis=1).round(2)
    
    # 3) Reorder columns: candidate_key, Average Score, then skills
    other_skills = [col for col in skill_columns if col != 'Average Score']  
    pivot = pivot[['candidate_key', 'Average Score'] + other_skills]
    
    total = len(pivot)
    st.info(f"ðŸ“Š **{total} candidates** in database")

    # === SEARCH AND FILTER SECTION ===
    st.markdown("#### ðŸ” Search & Filter")
    
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        # Search by candidate name
        search_term = st.text_input(
            "ðŸ” Search candidates",
            placeholder="Enter candidate name...",
            help="Search by candidate name (case-insensitive)"
        )
    
    with col2:
        # Filter by minimum score in any category
        min_score_filter = st.selectbox(
            "Minimum score (any skill)",
            options=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
            index=0,
            help="Show only candidates with at least this score in ANY skill"
        )
    
    with col3:
        # Sort options
        sort_options = ['Average Score'] + skill_columns
        sort_by = st.selectbox(
            "Sort by",
            options=sort_options,
            index=0,
            help="Column to sort by (descending)"
        )

    # === APPLY FILTERS AND SORTING ===
    filtered_pivot = pivot.copy()
    
    # Apply search filter
    if search_term:
        mask = filtered_pivot['candidate_key'].str.contains(search_term, case=False, na=False)
        filtered_pivot = filtered_pivot[mask]
        st.info(f"ðŸ” Search results: **{len(filtered_pivot)}** candidates match '{search_term}'")
    
    # Apply minimum score filter
    if min_score_filter > 0:
        mask = (filtered_pivot[skill_columns] >= min_score_filter).any(axis=1)
        filtered_pivot = filtered_pivot[mask]
        st.info(f"ðŸ“Š Filter results: **{len(filtered_pivot)}** candidates with score â‰¥{min_score_filter}")
    
    
    # CRITICAL FIX: Apply sorting BEFORE pagination
    filtered_pivot = filtered_pivot.sort_values(sort_by, ascending=False)
    
    # Show sorting info
    if sort_by != 'Average Score':
        st.info(f"ðŸ“Š Sorted by **{sort_by}** (highest to lowest)")

    if len(filtered_pivot) == 0:
        st.warning("âš ï¸ No candidates match your search/filter criteria.")
        return

    # === PAGINATION (AFTER SORTING) ===
    st.markdown("#### ðŸ“‹ Results")
    
    # Pagination controls
    col1, col2, col3, col4 = st.columns([1, 1, 1, 2])
    
    with col1:
        page_size = st.selectbox(
            "Results per page",
            options=[10, 20, 50, 100],
            index=1,  # Default to 20
            key="page_size"
        )
    
    with col2:
        total_pages = (len(filtered_pivot) - 1) // page_size + 1
        
        # Handle button clicks with query parameters (cleaner approach)
        if st.session_state.get("go_to_first", False):
            st.session_state["target_page"] = 1
            del st.session_state["go_to_first"]
        elif st.session_state.get("go_to_last", False):
            st.session_state["target_page"] = total_pages  
            del st.session_state["go_to_last"]
        
        # Get target page or use current value
        initial_page = st.session_state.get("target_page", 1)
        if "target_page" in st.session_state:
            del st.session_state["target_page"]
        
        current_page = st.number_input(
            f"Page (1-{total_pages})",
            min_value=1,
            max_value=total_pages,
            value=min(initial_page, total_pages),  # Ensure within bounds
            key="current_page"
        )
    
    with col3:
        st.metric("Showing", f"{len(filtered_pivot)} candidates")
        # Show current sort status
        if sort_by == 'Average Score':
            st.caption("ðŸ”„ Default sort")
        else:
            st.caption(f"ðŸ“Š By {sort_by}")
    
    with col4:
        # Quick jump to top/bottom - with conditional enabling
        col_a, col_b = st.columns(2)
        with col_a:
            # Disable "First Page" if already on page 1
            first_page_disabled = (current_page <= 1)
            if st.button(
                "â¬†ï¸ First Page", 
                use_container_width=True, 
                disabled=first_page_disabled,
                help="Go to first page" if not first_page_disabled else "Already on first page"
            ):
                st.session_state["go_to_first"] = True
                st.rerun()
        with col_b:
            # Disable "Last Page" if already on last page
            last_page_disabled = (current_page >= total_pages)
            if st.button(
                "â¬‡ï¸ Last Page", 
                use_container_width=True, 
                disabled=last_page_disabled,
                help="Go to last page" if not last_page_disabled else "Already on last page"
            ):
                st.session_state["go_to_last"] = True
                st.rerun()

    # === DISPLAY PAGINATED RESULTS (AFTER SORTING) ===
    start_idx = (current_page - 1) * page_size
    end_idx = start_idx + page_size
    paginated_df = filtered_pivot.iloc[start_idx:end_idx]
    
    # Show pagination info with sort context
    total_filtered = len(filtered_pivot)
    st.info(f"ðŸ“„ Showing entries {start_idx + 1}-{min(end_idx, total_filtered)} of {total_filtered} candidates (sorted by {sort_by})")

    # Remove candidate_key from display (used for filtering only)
    display_df = paginated_df.drop('candidate_key', axis=1)

    st.dataframe(display_df, use_container_width=True, height=600)


    # === SUMMARY STATISTICS FOR CURRENT VIEW ===
    st.markdown("#### ðŸ“Š Current View Statistics")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        avg_of_averages = paginated_df['Average Score'].mean()
        st.metric("ðŸ“ˆ Avg Score", f"{avg_of_averages:.2f}")
    
    with col2:
        top_performer = paginated_df['Average Score'].max()
        st.metric("ðŸ† Highest Avg", f"{top_performer:.2f}")
    
    with col3:
        # Find skill with highest max score in current view
        skill_maxes = paginated_df[skill_columns].max()
        best_skill = skill_maxes.idxmax()
        best_score = skill_maxes.max()
        st.metric("ðŸŽ¯ Best Skill Score", f"{best_score}")
        st.caption(f"in {best_skill}")
    
    with col4:
        # Count candidates with score >= 8 in any skill
        high_performers = (paginated_df[skill_columns] >= 8).any(axis=1).sum()
        st.metric("â­ High Performers", f"{high_performers}")
        st.caption("(score â‰¥8 in any skill)")

    # === DOWNLOAD OPTIONS ===
    st.markdown("---")
    col1, col2 = st.columns(2)
    
    with col1:
        # Download current filtered results
        csv_filtered = filtered_pivot.drop('candidate_key', axis=1).to_csv().encode("utf-8")
        st.download_button(
            "â¬‡ï¸ Download Filtered Results",
            csv_filtered,
            f"candidate_scores_filtered_{len(filtered_pivot)}_results.csv",
            "text/csv",
            use_container_width=True
        )
    
    with col2:
        # Download all results
        csv_all = pivot.drop('candidate_key', axis=1).to_csv().encode("utf-8")
        st.download_button(
            "â¬‡ï¸ Download All Results",
            csv_all,
            f"candidate_scores_all_{total}_candidates.csv",
            "text/csv",
            use_container_width=True
        )

    # === NEW: PDF LINKS SECTION ===
    st.markdown("---")
    st.markdown("#### ðŸ“„ Direct PDF Access")
    st.markdown("*Click the buttons below to view candidate PDFs directly in your browser*")
    
    # Show PDF links for current page candidates
    for candidate_name in paginated_df.index:
        candidate_files = file_mappings.get(candidate_name, {})
        
        with st.expander(f"ðŸ‘¤ **{candidate_name}**", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**ðŸ“Š Candidate Summary:**")
                row_data = paginated_df.loc[candidate_name]
                avg_score = row_data.get('Average Score', 0)
                st.metric("Average Score", f"{avg_score:.2f}")
                
                # Show top 3 skills
                skill_scores = {}
                for skill in other_skills:
                    if skill in row_data:
                        skill_scores[skill] = row_data[skill]
                
                if skill_scores:
                    # Sort by score and show top 3
                    top_skills = sorted(skill_scores.items(), key=lambda x: x[1], reverse=True)[:3]
                    st.markdown("**ðŸŽ¯ Top Skills:**")
                    for skill, score in top_skills:
                        st.write(f"â€¢ {skill}: **{score}**")
            
            with col2:
                st.markdown("**ðŸ“„ PDF Links:**")
                
                # MikoMiko PDF link
                if candidate_files.get('mikomiko_url'):
                    st.markdown(f"""
                    <a href="{candidate_files['mikomiko_url']}" target="_blank">
                        <button style="background-color: #4CAF50; color: white; padding: 10px 20px; border: none; border-radius: 5px; cursor: pointer; margin: 5px; width: 90%;">
                            ðŸ“‹ Open MikoMiko PDF
                        </button>
                    </a>
                    """, unsafe_allow_html=True)
                else:
                    st.info("ðŸ“‹ No MikoMiko PDF available")
                
                # Resume PDF link
                if candidate_files.get('resume_url'):
                    st.markdown(f"""
                    <a href="{candidate_files['resume_url']}" target="_blank">
                        <button style="background-color: #2196F3; color: white; padding: 10px 20px; border: none; border-radius: 5px; cursor: pointer; margin: 5px; width: 90%;">
                            ðŸ“„ Open Resume PDF
                        </button>
                    </a>
                    """, unsafe_allow_html=True)
                else:
                    st.info("ðŸ“„ No Resume PDF available")
                
                # Show file info
                st.markdown("**ðŸ“ File Info:**")
                if candidate_files.get('mikomiko_file'):
                    st.caption(f"ðŸ“‹ MikoMiko: {candidate_files['mikomiko_file']}")
                if candidate_files.get('resume_file'):
                    st.caption(f"ðŸ“„ Resume: {candidate_files['resume_file']}")


def render_delete_all_resumes() -> None:
    """
    Render the delete all resumes functionality.
    Also delete all PDF files from the server.
    """
    st.markdown("---")
    st.markdown("### ðŸ§¹ Bulk Delete All Data")
    st.warning("âš ï¸ This will permanently erase **all** candidate and resume data AND PDF files. Use with extreme caution!")

    # â”€â”€ A) If we just succeeded, show banner and clear flag â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if st.session_state.get("delete_success", False):
        st.success("âœ… All records and PDF files have been deleted.")
        # clear so it only shows once
        del st.session_state["delete_success"]

    # â”€â”€ B) Handle the confirm checkbox default (cleared after delete) â”€â”€
    if st.session_state.get("deleted_all_once", False):
        default_confirm = False
        del st.session_state["deleted_all_once"]
    else:
        default_confirm = st.session_state.get("confirm_delete_all", False)

    confirm = st.checkbox(
        "I understand this cannot be undone and will delete all PDF files",
        value=default_confirm,
        key="confirm_delete_all",
    )

    # â”€â”€ C) Single "Delete All" button â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if st.button("ðŸ—‘ï¸ DELETE ALL RECORDS & PDF FILES", key="delete_all_btn"):
        if not confirm:
            st.error("You must check the box above to delete everything.")
        else:
            try:
                # Import PDF server delete function
                from ..frontend.pdf_server import delete_all_pdf_files
                
                env = load_env_vars()
                conn = connect_postgres(env)
                cur = conn.cursor()
                
                print(f"ðŸ—‘ï¸ Starting bulk deletion of all data...")
                
                # Delete all PDF files from server (simplified approach)
                print(f"ðŸ—‘ï¸ Deleting all PDF files from server...")
                pdf_deletion_success = delete_all_pdf_files()
                
                if pdf_deletion_success:
                    print(f"âœ… All PDF files deleted from server")
                else:
                    print(f"âš ï¸ Warning: PDF file deletion may have failed")
                
                # Delete all database records
                print(f"ðŸ—‘ï¸ Deleting all database records...")
                cur.execute("""
                    TRUNCATE TABLE
                      public.resumes_metadata,
                      public.resumes_normal,
                      public.resume_category_score
                    RESTART IDENTITY CASCADE;
                """)
                conn.commit()
                cur.close()
                conn.close()

                print(f"âœ… Deleted all database records and PDF files")

                # instead of st.success(), set a flag and rerun
                st.session_state["delete_success"] = True
                st.session_state["deleted_all_once"] = True
                st.rerun()

            except Exception as e:
                print(f"âŒ Error deleting all records: {e}")
                st.error(f"âŒ Failed to delete all records: {e}")

def render_job_description_main_content() -> None:
    """Main content area for job description processing."""
    print("ðŸ”¥" * 30)
    print("render_job_description_main_content() CALLED!")
    print("ðŸ”¥" * 30)
    
    st.markdown("### ðŸ“„ Job Description Analysis")
    st.markdown("Upload a job description PDF to extract required skills and save them to the database.")
    
    uploaded_file = st.file_uploader(
        "Choose a job description PDF",
        type=["pdf"],
        help="Upload a PDF containing the job description to analyze"
    )
    
    print(f"ðŸ“ File uploaded: {uploaded_file is not None}")
    if uploaded_file:
        print(f"ðŸ“ File name: {uploaded_file.name}")
        print(f"ðŸ“ File size: {uploaded_file.size}")
    
    if uploaded_file is not None:
        print("ðŸš€ Starting job description processing...")
        try:
            process_job_description_pdf(uploaded_file)
            print("âœ… Job description processing completed")
        except Exception as e:
            print(f"âŒ Error in process_job_description_pdf: {e}")
            st.error(f"Error processing job description: {e}")
    else:
        print("â³ Waiting for file upload...")
        st.info("ðŸ‘† Please upload a job description PDF to begin analysis")

def process_job_description_pdf(uploaded_file):
    """
    Process the uploaded job description PDF and extract skills.
    """
    try:
        # Step 1: Extract text from PDF
        with st.spinner("ðŸ” Extracting text from PDF..."):
            extracted_text = extract_pdf_text_with_ocr(uploaded_file)
            
            if not extracted_text or len(extracted_text.strip()) < 50:
                print("âŒ Could not extract sufficient text from PDF. Please check if the PDF contains readable text.")
                return
            
            st.success(f"âœ… Extracted {len(extracted_text)} characters from PDF!")
            
            # Show preview of extracted text
            with st.expander("ðŸ“– Preview Extracted Text"):
                preview_text = extracted_text[:2000] + "..." if len(extracted_text) > 2000 else extracted_text
                st.text_area("Full extracted content:", preview_text, height=300, disabled=True)
        
        # Step 2: AI Analysis
        with st.spinner("ðŸ¤– Analyzing job requirements with AI..."):
            extracted_skills = extract_skills_from_job_description(extracted_text)
            
            if not extracted_skills:
                print("âŒ No skills could be extracted from the job description")
                return
            
            st.success(f"ðŸŽ¯ Found {len(extracted_skills)} skill categories!")
        
        # Step 3: Display extracted skills
        st.markdown("#### ðŸ› ï¸ Extracted Skills")
        
        # Group skills by category for better display
        skill_categories = categorize_extracted_skills(extracted_skills)
        
        if skill_categories:
            # Create tabs for each category
            tab_names = list(skill_categories.keys())
            tabs = st.tabs(tab_names)
            
            for i, (category, skills) in enumerate(skill_categories.items()):
                with tabs[i]:
                    cols = st.columns(2)
                    mid_point = len(skills) // 2
                    
                    with cols[0]:
                        for skill in skills[:mid_point]:
                            st.write(f"â€¢ **{skill}**")
                    
                    with cols[1]:
                        for skill in skills[mid_point:]:
                            st.write(f"â€¢ **{skill}**")
        else:
            # Simple two-column layout if categorization fails
            col1, col2 = st.columns(2)
            mid_point = len(extracted_skills) // 2
            
            with col1:
                for skill in extracted_skills[:mid_point]:
                    st.write(f"â€¢ **{skill}**")
            
            with col2:
                for skill in extracted_skills[mid_point:]:
                    st.write(f"â€¢ **{skill}**")
        
        # Step 4: Save options
        st.markdown("---")
        st.markdown("#### ðŸ’¾ Save to Database")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            clear_existing = st.checkbox(
                "ðŸ§¹ Clear existing skill categories first",
                value=True,
                help="Recommended: Remove all existing skills before adding new ones"
            )
        
        with col2:
            save_button = st.button(
                "ðŸ’¾ Save Skills to Database", 
                type="secondary", 
                use_container_width=True
            )
        
        if save_button:
            print("=" * 60)
            print("DEBUG: Save button clicked!")
            print(f"DEBUG: Skills to save: {extracted_skills}")
            print(f"DEBUG: Clear existing: {clear_existing}")
            print("=" * 60)
            
            with st.spinner("ðŸ’¾ Saving skills to database..."):
                result = save_job_skills_to_database(extracted_skills, clear_existing)
                
                print("-" * 40)
                print(f"DEBUG: Save result: {result}")
                print("-" * 40)
                
                if result['success']:
                    if clear_existing:
                        st.success(f"âœ… Cleared {result['deleted_count']} existing skills and saved {result['added_count']} new skill categories!")
                    else:
                        st.success(f"âœ… Added {result['added_count']} new skill categories! ({result['duplicate_count']} were already in database)")
                    
                    # Show summary
                    st.balloons()
                    st.info("ðŸ”„ Page will refresh to show updated categories...")
                    time.sleep(2)
                    st.rerun()
                else:
                    print(f"âŒ Error saving skills: {result.get('error', 'Unknown error')}")
                    
    except Exception as e:
        print(f"âŒ Error processing job description: {str(e)}")
        print(f"ERROR in process_job_description_pdf: {e}")
        
# Add all the helper functions here...
def extract_pdf_text_with_ocr(uploaded_file) -> str:
    """Extract text from uploaded PDF file using OCR and text extraction."""
    import fitz  # PyMuPDF
    from pdf2image import convert_from_bytes
    import pytesseract
    from PIL import Image
    import io
    
    try:
        # First, try direct text extraction with PyMuPDF
        pdf_bytes = uploaded_file.read()
        uploaded_file.seek(0)  # Reset file pointer
        
        # Method 1: Direct text extraction
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        direct_text = ""
        
        for page_num in range(doc.page_count):
            page = doc[page_num]
            direct_text += page.get_text()
        
        doc.close()
        
        # If we got good text directly, use it
        if len(direct_text.strip()) > 100:  # Reasonable amount of text
            return direct_text.strip()
        
        # Method 2: OCR if direct extraction failed
        st.info("ðŸ“¸ Direct text extraction yielded limited results. Using OCR...")
        
        # Convert PDF to images
        images = convert_from_bytes(pdf_bytes, dpi=300)
        
        ocr_text = ""
        for i, image in enumerate(images):
            # Use pytesseract for OCR
            page_text = pytesseract.image_to_string(image, lang='eng')
            ocr_text += f"\n--- Page {i+1} ---\n{page_text}"
        
        return ocr_text.strip()
        
    except Exception as e:
        raise Exception(f"Failed to extract text from PDF: {str(e)}")


def extract_skills_from_job_description(job_text: str) -> List[str]:
    """Use AI to extract skill categories from job description text."""
    from ..backend.model import Qwen2VLClient
    
    # Initialize Qwen client
    qwen = Qwen2VLClient(
        host="http://localhost",
        port=8001,
        model="Qwen/Qwen2.5-VL-7B-Instruct",
        temperature=0.0
    )
    
    SKILLS_EXTRACTION_PROMPT = f"""
You are an expert HR analyst. Analyze the following job description and extract ALL technical skills, tools, technologies, and competencies required for this position.

JOB DESCRIPTION:
{job_text}

Your task:
1. Read the job description carefully
2. Extract EVERY technical skill, programming language, framework, tool, platform, methodology, or domain knowledge mentioned
3. Include both explicitly mentioned skills AND implied skills
4. Return ONLY a JSON array of skill names

EXAMPLE OUTPUT:
["Python", "JavaScript", "React", "Node.js", "SQL", "PostgreSQL", "AWS", "Docker", "Git", "Agile", "REST APIs", "Machine Learning", "Data Analysis", "Linux", "CI/CD"]

RULES:
- Include programming languages, frameworks, libraries, databases, cloud platforms, tools, methodologies
- Use standard, widely-recognized names
- Be comprehensive but avoid duplicates
- Don't include soft skills
- Each skill should be 1-4 words maximum
- Return ONLY the JSON array, no additional text

JSON Array of Skills:
"""
    
    try:
        reply = qwen.chat_completion(
            question=SKILLS_EXTRACTION_PROMPT,
            system_prompt="You are an expert at extracting technical skills from job descriptions. Return only clean JSON arrays."
        ).strip()
        
        # Clean up response
        if reply.startswith("```"):
            import re
            json_match = re.search(r'\[.*\]', reply, re.DOTALL)
            if json_match:
                reply = json_match.group(0)
        
        # Parse JSON
        import json
        skills = json.loads(reply)
        
        if isinstance(skills, list):
            # Clean and validate skills
            cleaned_skills = []
            for skill in skills:
                if isinstance(skill, str) and len(skill.strip()) > 0:
                    cleaned_skill = skill.strip().title()  # Proper case
                    if cleaned_skill not in cleaned_skills:  # Avoid duplicates
                        cleaned_skills.append(cleaned_skill)
            
            return cleaned_skills
        else:
            raise ValueError("Response is not a list")
            
    except Exception as e:
        print(f"Error parsing AI response: {e}")
        # Fallback: try to extract skills manually
        return extract_skills_fallback(job_text)
    
def extract_skills_fallback(job_text: str) -> List[str]:
    """Fallback method to extract skills using keyword matching."""
    import re
    
    # Common technical skills to look for
    skill_patterns = [
        r'\b(Python|Java|JavaScript|TypeScript|C\+\+|C#|PHP|Ruby|Go|Kotlin|Swift|Scala|R)\b',
        r'\b(HTML|CSS|React|Vue|Angular|Node\.js|Express|Django|Flask|Laravel|Spring)\b',
        r'\b(SQL|MySQL|PostgreSQL|MongoDB|Redis|Oracle|SQLite)\b',
        r'\b(AWS|Azure|GCP|Docker|Kubernetes|Jenkins|GitLab|CI/CD|Terraform)\b',
        r'\b(Git|GitHub|Jira|Confluence|Linux|Unix|Windows|Mac)\b',
        r'\b(Agile|Scrum|DevOps|TDD|API|REST|GraphQL)\b',
        r'\b(Machine Learning|Data Science|AI|Analytics|Pandas|NumPy|TensorFlow|PyTorch)\b'
    ]
    
    found_skills = set()
    
    for pattern in skill_patterns:
        matches = re.findall(pattern, job_text, re.IGNORECASE)
        for match in matches:
            found_skills.add(match.title())
    
    return list(found_skills) if found_skills else ["Web Development", "Programming", "Database Management"]


def categorize_extracted_skills(skills: List[str]) -> Dict[str, List[str]]:
    """Organize skills into logical categories."""
    categories = {
        "Programming Languages": [],
        "Web Technologies": [],
        "Databases & Storage": [],
        "Cloud & DevOps": [],
        "Tools & Platforms": [],
        "Methodologies": [],
        "Other Skills": []
    }
    
    categorization_rules = {
        "Programming Languages": ["python", "java", "javascript", "typescript", "c++", "c#", "php", "ruby", "go", "kotlin", "swift", "scala", "r"],
        "Web Technologies": ["html", "css", "react", "vue", "angular", "node.js", "express", "django", "flask", "laravel", "spring", "rest", "api"],
        "Databases & Storage": ["sql", "mysql", "postgresql", "mongodb", "redis", "oracle", "sqlite", "database"],
        "Cloud & DevOps": ["aws", "azure", "gcp", "docker", "kubernetes", "jenkins", "gitlab", "ci/cd", "terraform", "devops"],
        "Tools & Platforms": ["git", "github", "jira", "confluence", "linux", "unix", "windows", "mac"],
        "Methodologies": ["agile", "scrum", "tdd", "machine learning", "data science", "ai", "analytics"]
    }
    
    for skill in skills:
        skill_lower = skill.lower()
        categorized = False
        
        for category, keywords in categorization_rules.items():
            if any(keyword in skill_lower for keyword in keywords):
                categories[category].append(skill)
                categorized = True
                break
        
        if not categorized:
            categories["Other Skills"].append(skill)
    
    # Remove empty categories
    return {k: v for k, v in categories.items() if v}



def save_job_skills_to_database(skills: List[str], clear_existing: bool = True) -> Dict[str, any]:
    """Save extracted skills to the skill_category table."""
    try:
        print("=" * 50)
        print("SAVING SKILLS TO DATABASE")
        print("=" * 50)
        print(f"Skills to save: {skills}")
        print(f"Clear existing: {clear_existing}")
        print(f"Number of skills: {len(skills)}")
        
        env = load_env_vars()
        print(f"Environment loaded: {bool(env)}")
        
        conn = connect_postgres(env)
        print("Database connection established")
        
        cur = conn.cursor()
        
        deleted_count = 0
        added_count = 0
        duplicate_count = 0
        
        # Clear existing skills if requested
        if clear_existing:
            print("Clearing existing skills...")
            cur.execute("SELECT COUNT(*) FROM skill_category;")
            deleted_count = cur.fetchone()[0]
            print(f"Found {deleted_count} existing skills to delete")
            
            cur.execute("TRUNCATE TABLE skill_category RESTART IDENTITY CASCADE;")
            print("Existing skills cleared")
        
        # Insert new skills
        print("Inserting new skills...")
        for i, skill in enumerate(skills, 1):
            print(f"Processing skill {i}/{len(skills)}: '{skill}'")
            
            cur.execute("""
                INSERT INTO skill_category(name)
                VALUES (LOWER(%s))
                ON CONFLICT(name) DO NOTHING
                RETURNING name;
            """, (skill,))
            
            result = cur.fetchone()
            if result:
                added_count += 1
                print(f"  âœ… Added: {skill}")
            else:
                duplicate_count += 1
                print(f"  âš ï¸ Duplicate (skipped): {skill}")
        
        conn.commit()
        print("Database changes committed")
        
        cur.close()
        conn.close()
        print("Database connection closed")
        
        final_result = {
            'success': True,
            'added_count': added_count,
            'duplicate_count': duplicate_count,
            'deleted_count': deleted_count
        }
        
        print("-" * 50)
        print("FINAL RESULT:")
        print(f"Success: {final_result['success']}")
        print(f"Added: {final_result['added_count']}")
        print(f"Duplicates: {final_result['duplicate_count']}")
        print(f"Deleted: {final_result['deleted_count']}")
        print("=" * 50)
        
        return final_result
        
    except Exception as e:
        error_msg = str(e)
        print("!" * 50)
        print("ERROR SAVING SKILLS:")
        print(f"Error: {error_msg}")
        print("!" * 50)
        
        return {
            'success': False,
            'error': error_msg,
            'added_count': 0,
            'duplicate_count': 0,
            'deleted_count': 0
        }